{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import imageio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.applications import resnet\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "#If you are running from colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Running on CoLab')\n",
    "    directory = r'/content/drive/Shareddrives/cancer-detection-model/TEST lung cancer dataset'\n",
    "else:\n",
    "    #    If you want to run local\n",
    "    print('Not running on CoLab')\n",
    "    directory = r'../../data/cancer-detection-model/TEST lung cancer dataset'\n",
    "\n",
    "categories = ['Benign cases', 'Malignant cases', 'Normal cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_generator(directory, image_height, image_width, batch_size):\n",
    "    '''Build generators for train and validatio\n",
    "        :directory: Location of the data\n",
    "        :image_height: image height\n",
    "        :image_width: image width\n",
    "        :batch_size: The batch size\n",
    "    '''\n",
    "\n",
    "    datagen = ImageDataGenerator(dtype='float32',\n",
    "        rescale=1.0 / 255.0)\n",
    "\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(image_height, image_width, 1),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical',  # 'categorical' for multi-class classification\n",
    "        shuffle=False,\n",
    "        classes={'Benign cases': 0, \n",
    "                 'Malignant cases': 1, \n",
    "                 'Normal cases': 2}\n",
    "    )\n",
    "\n",
    "    return test_generator\n",
    "\n",
    "def process_normalize(directory, categories, image_size):\n",
    "    '''Process and normalize images\n",
    "        :directory: Root directory of images\n",
    "        :categories: Categories of diagnosis\n",
    "        :image_size: Target image size to resize\n",
    "    '''\n",
    "    data = []\n",
    "    X, y = [], []\n",
    "\n",
    "    for category_index, category in enumerate(categories):\n",
    "        path = os.path.join(directory, category)\n",
    "\n",
    "        # Iterate through images and capture image data, resize it and capture category index\n",
    "        for file in os.listdir(path):\n",
    "            file_extension = pathlib.Path(file).suffix\n",
    "            if any(ext in file_extension for ext in ['jpg', 'jpeg', 'png']):\n",
    "                filepath = os.path.join(path, file)\n",
    "                img = cv2.imread(filepath, 0)\n",
    "                # resize the image\n",
    "                img = cv2.resize(img, (image_size, image_size))\n",
    "                data.append([img, category_index])\n",
    "            else:\n",
    "                print('Skipping {}'.format(file))\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Split out the image and category data\n",
    "    image_data, category_data = map(list, zip(*data))\n",
    "    # Convert the category index into a vector ala [0, 1, 0] because we do\n",
    "    # not want to imply in the model that index 0 is not as good as 1 and 2 is better than 1 etc.\n",
    "    y = keras.utils.to_categorical(category_data)\n",
    "\n",
    "    X = np.array(image_data).reshape(-1, image_size, image_size, 1)\n",
    "\n",
    "    print('X counts:', X.shape)\n",
    "    print('y counts:', y.shape)\n",
    "\n",
    "    # Normalize image values to be between the values of 0 and 1\n",
    "    X = X / 255.0\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping .gitignore\n",
      "X counts: (315, 256, 256, 1)\n",
      "y counts: (315, 3)\n",
      "X counts: (4738, 256, 256, 1)\n",
      "y counts: (4738, 3)\n"
     ]
    }
   ],
   "source": [
    "X, y = process_normalize(directory, categories, 256)\n",
    "\n",
    "# Try the luna dataset\n",
    "directory = r'../../data/cancer-detection-model/luna16-jpg for testing'\n",
    "categories = ['Benign', 'Malignant', 'Normal']\n",
    "X_luna, y_luna = process_normalize(directory, categories, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 76ms/step - loss: 0.1672 - accuracy: 0.9492\n",
      "lung_cancer_detection_One.data_augmentation-model4 for standard Test Loss: 0.16715845465660095, Test Accuracy: 0.9492063522338867\n",
      "593/593 [==============================] - 44s 74ms/step - loss: 6.1796 - accuracy: 0.2478\n",
      "lung_cancer_detection_One.data_augmentation-model4 for luna16 Test Loss: 6.179551601409912, Test Accuracy: 0.2477838695049286\n"
     ]
    }
   ],
   "source": [
    "models = {'lung_cancer_detection_One.data_augmentation-model4':\n",
    "          {'image_height': 256, 'image_width': 256, 'batch_size': 8}}\n",
    "\n",
    "\n",
    "for model, value in models.items():\n",
    "    # To load the model architecture and weights in a new session:\n",
    "    loaded_model = tf.keras.models.load_model(model)\n",
    "\n",
    "    # Compile the loaded model\n",
    "    loaded_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    results = loaded_model.evaluate(X, y, batch_size=value['batch_size'])\n",
    "    print(f\"{model} for standard Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n",
    "        # To load the model architecture and weights in a new session:\n",
    "    loaded_model = tf.keras.models.load_model(model)\n",
    "\n",
    "    # Compile the loaded model\n",
    "    loaded_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    results = loaded_model.evaluate(X_luna, y_luna, batch_size=value['batch_size'])\n",
    "    print(f\"{model} for luna16 Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
