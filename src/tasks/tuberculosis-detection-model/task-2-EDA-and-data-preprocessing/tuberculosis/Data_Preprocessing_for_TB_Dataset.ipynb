{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR4Re82w5Zyg",
        "outputId": "3dc1e1e9-17ce-480b-b5a9-698b60e932a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages"
      ],
      "metadata": {
        "id": "-b7ChlbsQ_74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2"
      ],
      "metadata": {
        "id": "0-EkRJeDRDM8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Train and Validation Datasets"
      ],
      "metadata": {
        "id": "PMaeaB8TRGaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k2jF5LI5Fca",
        "outputId": "63eb8bcb-89ac-4435-b1f6-7732373b5f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images:  9912\n",
            "Training:  7929\n",
            "Validation:  1983\n"
          ]
        }
      ],
      "source": [
        "# Define directory\n",
        "root_dir = '/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/original'\n",
        "output_dir = '/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/original/output'\n",
        "\n",
        "# Create directories for training, validation sets.\n",
        "for folder in ['train', 'val']:\n",
        "    for cls in ['Non-Tuberculosis', 'Tuberculosis']:\n",
        "        os.makedirs(os.path.join(output_dir, folder, cls))\n",
        "\n",
        "# Creating partitions of the data after shuffling.\n",
        "current_cls = 'Non-Tuberculosis'\n",
        "src = os.path.join(root_dir, current_cls)\n",
        "all_file_names_0 = os.listdir(src)\n",
        "np.random.shuffle(all_file_names_0)\n",
        "train_file_names_0, val_file_names_0 = np.split(np.array(all_file_names_0), [int(len(all_file_names_0) * 0.8)])\n",
        "train_file_names_0 = [os.path.join(src, name) for name in train_file_names_0.tolist()]\n",
        "val_file_names_0 = [os.path.join(src, name) for name in val_file_names_0.tolist()]\n",
        "\n",
        "# Move the images to the corresponding folders in the output directory.\n",
        "for file_name in tqdm(train_file_names_0):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'train', current_cls))\n",
        "\n",
        "for file_name in tqdm(val_file_names_0):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'val', current_cls))\n",
        "\n",
        "# Move to the next class\n",
        "current_cls = 'Tuberculosis'\n",
        "src = os.path.join(root_dir, current_cls)  # Folder to copy images from.\n",
        "all_file_names_1 = os.listdir(src)\n",
        "np.random.shuffle(all_file_names_1)\n",
        "train_file_names_1, val_file_names_1 = np.split(np.array(all_file_names_1), [int(len(all_file_names_1) * 0.8)])\n",
        "train_file_names_1 = [os.path.join(src, name) for name in train_file_names_1.tolist()]\n",
        "val_file_names_1 = [os.path.join(src, name) for name in val_file_names_1.tolist()]\n",
        "\n",
        "# Move the images to the corresponding folders in the output directory.\n",
        "for file_name in tqdm(train_file_names_1):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'train', current_cls))\n",
        "\n",
        "for file_name in tqdm(val_file_names_1):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'val', current_cls))\n",
        "\n",
        "all_file_names = all_file_names_0 + all_file_names_1\n",
        "train_file_names = train_file_names_0 + train_file_names_1\n",
        "val_file_names = val_file_names_0 + val_file_names_1\n",
        "\n",
        "print('Total images: ', len(all_file_names))\n",
        "print('Training: ', len(train_file_names))\n",
        "print('Validation: ', len(val_file_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating augmented dataset"
      ],
      "metadata": {
        "id": "JLWX8JdURSCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all .txt files in the /path/to/directory\n",
        "files = glob('/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/augmented/*.png')\n",
        "for f in files:\n",
        "    try:\n",
        "        os.remove(f)\n",
        "    except OSError as e:\n",
        "        print(f\"Error: {f} - {e.strerror}\")"
      ],
      "metadata": {
        "id": "c8VKab67hXab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/augmented'"
      ],
      "metadata": {
        "id": "i4HM2hYoRVUB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining augmentation pipeline\n",
        "transform = A.Compose([\n",
        "    A.Transpose(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightness(limit=0.3, p=0.5),\n",
        "    A.RandomContrast(limit=0.3, p=0.5),\n",
        "    A.CLAHE(clip_limit=4.0, p=0.3),\n",
        "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.3),\n",
        "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, border_mode=0, p=0.4),\n",
        "    A.Resize(256, 256)\n",
        "])\n",
        "\n",
        "full_paths = glob('/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/augmented/Tuberculosis/*.png')\n",
        "filenames = os.listdir('/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/augmented/Tuberculosis')\n",
        "\n",
        "def visualize(image):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "image = cv2.imread(full_paths[0])\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "transformed = transform(image=image)\n",
        "aug_img = transformed['image']\n",
        "aug_img = cv2.resize(aug_img, (255, 255))\n",
        "visualize(aug_img)\n",
        "\n",
        "for i in range(0, len(full_paths)):\n",
        "    image = cv2.imread(full_paths[i], cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    transformed = transform(image=image)\n",
        "    aug_img = transformed['image']\n",
        "    aug_img = cv2.resize(aug_img, (255, 255))\n",
        "    cv2.imwrite((os.path.join(root_dir, f\"Augmented TB/aug_{filenames[i]}\")), aug_img)"
      ],
      "metadata": {
        "id": "Kg9LchzFpZzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directory\n",
        "root_dir = '/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/augmented'\n",
        "output_dir = '/drive/MyDrive/Datasets/Omdena Myanmar/tuberculosis-detection-model/augmented/output'\n",
        "\n",
        "# Create directories for training, validation sets.\n",
        "for folder in ['train', 'val']:\n",
        "    for cls in ['Non-Tuberculosis', 'Tuberculosis']:\n",
        "        os.makedirs(os.path.join(output_dir, folder, cls))\n",
        "\n",
        "# Creating partitions of the data after shuffling.\n",
        "current_cls = 'Non-Tuberculosis'\n",
        "src = os.path.join(root_dir, current_cls)\n",
        "all_file_names_0 = os.listdir(src)\n",
        "np.random.shuffle(all_file_names_0)\n",
        "train_file_names_0, val_file_names_0 = np.split(np.array(all_file_names_0), [int(len(all_file_names_0) * 0.8)])\n",
        "train_file_names_0 = [os.path.join(src, name) for name in train_file_names_0.tolist()]\n",
        "val_file_names_0 = [os.path.join(src, name) for name in val_file_names_0.tolist()]\n",
        "\n",
        "# Move the images to the corresponding folders in the output directory.\n",
        "for file_name in tqdm(train_file_names_0):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'train', current_cls))\n",
        "\n",
        "for file_name in tqdm(val_file_names_0):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'val', current_cls))\n",
        "\n",
        "# Move to the next class\n",
        "current_cls_1 = 'Tuberculosis'\n",
        "src_1 = os.path.join(root_dir, current_cls_1)  # Folder to copy images from.\n",
        "tb_file_names = ['Tuberculosis/' + str(x) for x in os.listdir(src_1)]\n",
        "\n",
        "current_cls_2 = 'Augmented TB'\n",
        "src_2 = os.path.join(root_dir, current_cls_2)  # Folder to copy images from.\n",
        "aug_tb_file_names = ['Augmented TB/' + str(x) for x in os.listdir(src_2)]\n",
        "\n",
        "all_file_names_1 = tb_file_names + aug_tb_file_names\n",
        "np.random.shuffle(all_file_names_1)\n",
        "train_file_names_1, val_file_names_1 = np.split(np.array(all_file_names_1), [int(len(all_file_names_1) * 0.8)])\n",
        "train_file_names_1 = [os.path.join(root_dir, name) for name in train_file_names_1.tolist()]\n",
        "val_file_names_1 = [os.path.join(root_dir, name) for name in val_file_names_1.tolist()]\n",
        "\n",
        "# Move the images to the corresponding folders in the output directory.\n",
        "for file_name in tqdm(train_file_names_1):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'train', current_cls))\n",
        "\n",
        "for file_name in tqdm(val_file_names_1):\n",
        "    shutil.copy(file_name, os.path.join(output_dir, 'val', current_cls))\n",
        "\n",
        "all_file_names = all_file_names_0 + all_file_names_1\n",
        "train_file_names = train_file_names_0 + train_file_names_1\n",
        "val_file_names = val_file_names_0 + val_file_names_1\n",
        "\n",
        "print('Total images: ', len(all_file_names))\n",
        "print('Training: ', len(train_file_names))\n",
        "print('Validation: ', len(val_file_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG3hBj11lh4x",
        "outputId": "4221f007-7231-4775-813d-32997fc5ebf4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6047/6047 [02:25<00:00, 41.70it/s]\n",
            "100%|██████████| 1512/1512 [00:37<00:00, 40.11it/s]\n",
            "100%|██████████| 3723/3723 [02:03<00:00, 30.15it/s]\n",
            "100%|██████████| 931/931 [00:29<00:00, 31.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images:  12213\n",
            "Training:  9770\n",
            "Validation:  2443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}